# 神经网络（Neural Network）
### 算法概述  
- **类型**：监督学习  
- **核心思想**：通过多层连接的神经元模拟非线性关系  
- **典型任务**：分类、回归  
### 核心流程  
1. **前向传播**  
   * 输入数据逐层计算，每层公式：  
   \( z^{(l)} = W^{(l)}a^{(l-1)} + b^{(l)} \),  
   \( a^{(l)} = f(z^{(l)}) \)  
   - \( W \): 权重矩阵  
   - \( b \): 偏置向量  
   - \( f \): 激活函数（如 ReLU）  
2. **损失计算**  
    * 常用交叉熵（分类）或均方误差（回归）：  
   \( \mathcal{L} = \frac{1}{N}\sum (y_i - \hat{y}_i)^2 \)  
3. **反向传播**
    * 通过链式法则计算梯度，更新参数：  
   \( W \leftarrow W - \eta \cdot \frac{\partial \mathcal{L}}{\partial W} \) 
#### 优势
* 可拟合复杂非线性关系
* 支持端到端学习
* 结构灵活（可调整隐藏层数和神经元数）
#### 局限性
* 需要大量数据
* 训练计算成本高
* 超参数调优复杂
### 超参数  
- **学习率（η）**：控制参数更新步长  
- **批量大小**：单次训练样本数（影响梯度稳定性）  
- **隐藏层神经元数**：过多易过拟合，过少欠拟合  
