# 决策树（Decision Tree）
### 算法概述
  - **类型**：监督学习算法
  - **任务**：分类、回归
  - **核心思想**：通过特征分裂构建树形结果，实现数据划分
### 核心流程
  1. **节点分裂**
     * 选择最佳特征和分割点，最大化信息增益或最小化基尼不纯度
     * 指标公式：
       - 信息增益：`InfoGain = H(parent) - Σ (N_child/N * H(child))`  
       - 基尼指数：`Gini = 1 - Σ p_i^2`
  2. **递归建树**
     * 对子节点重复分裂过程，直到满足终止条件（如深度限制、节点纯度阈值）
  3. **剪枝优化**
#### 优势
  * 可解释性强（可视化决策路线）
  * 支持类别型和数值型特征
  * 无需特征标准化
#### 局限性
  * 容易过拟合（需剪枝优化）
  * 对数据分布敏感（需特征缩放）
  * 不稳定（微小数据变化可能改变树结构）
