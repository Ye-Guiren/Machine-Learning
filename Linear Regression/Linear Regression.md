# 线性回归（Linear Regression）
### 算法概述
  - **类型**：监督学习算法
  - **任务**：回归
  - **核心假设**：目标值与特征间存在线性关系
### 核心思想
  1. **模型定义**
     * 假设目标值 `y` 与特征 `X` 满足线性关系：  
     `y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε`
  2. **参数求解**
     *  通过**最小二乘法**优化，最小化预测值与真实值的平方和误差：  
     `argmin(Σ(y_i - ŷ_i)^2)`
  3. **闭式解**
     * 参数矩阵解：`β = (XᵀX)⁻¹Xᵀy`（当 `XᵀX` 可逆时）
#### 优势
  * 计算效率高（解析解存时）
  * 可解释性强（系数代表特征重要性）
  * 易扩展（如多项式回归）
#### 局限性
  * 对多重共线敏感
  * 假设严格得线性关系
  * 对异常值敏感
### 正则化变种
- **岭回归（Ridge）**  
  加入 L2 正则化项：`argmin(Σ(y_i - ŷ_i)^2 + λ||β||²`  
- **Lasso回归**  
  加入 L1 正则化项：`argmin(Σ(y_i - ŷ_i)^2 + λ|β|`  
