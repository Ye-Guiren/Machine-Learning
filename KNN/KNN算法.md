# KNN（K-Nearest Neighbors,k近邻）
### 算法概述
  类型：监督学习算法
  任务：分类、回归
  核心假设：相似样本在特征空间中距离相近
### 核心思想
  1. 距离计算：对待预测样本，计算其与训练集中所有样本的欧氏距离（或曼哈顿距离、余弦相似度等）
  2. 邻居选择：选取距离最近的K个样本（K为超参数，需手动设定，或使用网格搜索）
  3. 结果预测：
     * 分类任务：K个邻居中出现次数最多的类别作为预测结果（多数投票法）
     * 回归任务：K个邻居标签值得平均值作为预测结果
#### 优势
  * 无需训练过程（惰性学习）
  * 天然支持多分类任务
  * 可解释性强
#### 局限性
  * 预测时计算复杂度高
  * 对高维数据和噪声敏感
  * 需要合理选择K值和距离度量
            
